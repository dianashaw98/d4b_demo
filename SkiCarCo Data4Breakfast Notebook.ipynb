{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "NotebookSetup",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "import streamlit as st\nimport pandas as pd\nimport requests\nimport json\n\n# Import Snowpark context for the active session\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1066026a-0825-48f7-b021-e39842d49bdd",
   "metadata": {
    "name": "Introduction",
    "collapsed": false,
    "resultHeight": 535
   },
   "source": "# **Query Snowflake Cortex Analyst API via Slack**\n\nThis notebook demonstrates how to integrate **Snowflake Cortex Analyst API** for real-time data analysis via **Slack**. Users can ask **natural language questions** in Slack, and Snowflake will use **Cortex Analyst** to generate SQL queries and provide instant answers.\n\n### **End Result**\n\n1. **Slack**: You ask a question, such as **\"What's the average shipping time from Snowtires Automotive?\"**\n2. **Snowflake**: Using **Cortex Analyst API**, Snowflake generates the corresponding SQL and returns the result.\n\n### **Step 1: Ask a Question via Slack**\nAsk a question like **`/askcortex What's the average shipping time from Snowtires Automotive?`**. This triggers Snowflake to generate the SQL and provide the answer.\n\nExample Output:\\\n**Answer:**\\\nAVERAGE_SHIPPING_TIME\\\n5.200000\n\n`SELECT DISTINCT average_shipping_time FROM skicar.skicar_schema.supply_chain WHERE supplier_vendor_name = 'Snowtires Automotive' UNION SELECT 'Other Suppliers' AS supplier_vendor_name, AVG(average_shipping_time) FROM (SELECT DISTINCT (supplier_vendor_name), average_shipping_time FROM skicar.skicar_schema.supply_chain WHERE supplier_vendor_name <> 'Snowtires Automotive')\n -- Generated by Cortex Analyst\n;`"
  },
  {
   "cell_type": "markdown",
   "id": "db19107d-283e-4945-a60a-b8d952a4e318",
   "metadata": {
    "name": "SnowflakeSetup",
    "collapsed": false,
    "resultHeight": 243
   },
   "source": "## Snowflake Setup\n\nThe core components of the demo in Snowflake include:\n\n- **Cortex Service Role**: This role allows us to interact with the Cortex API.\n- **Warehouse**: Powers the queries executed by the Analyst.\n- **Schemas and Tables**: We’ve set up the required schemas and tables, such as `SUPPLY_CHAIN` and `PRODUCT_INFO` for querying order details.\n\nHere’s the SQL used to set it up:"
  },
  {
   "cell_type": "code",
   "id": "112a6db9-e0c2-4944-9754-14e21c9037bd",
   "metadata": {
    "language": "sql",
    "name": "SnowflakeSetupSQL"
   },
   "outputs": [],
   "source": "-- Create role and grant permissions\nCREATE ROLE IF NOT EXISTS CORTEX_SERVICE_ROLE;\nGRANT ROLE CORTEX_SERVICE_ROLE TO USER D4B;\n\n-- Setup the Warehouse\nCREATE OR REPLACE WAREHOUSE SKICAR WAREHOUSE_SIZE = XSMALL AUTO_SUSPEND = 60;\nUSE WAREHOUSE SKICAR;\n\n-- Grant access to the warehouse\nGRANT USAGE ON WAREHOUSE SKICAR TO ROLE CORTEX_SERVICE_ROLE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e3a6f5c-38cf-43d3-b830-ccfe5109635e",
   "metadata": {
    "name": "DataIngestion",
    "collapsed": false,
    "resultHeight": 143
   },
   "source": "## Data Ingestion\n\nFor this demo, we access data from two sources:\n\n1. **SharePoint**: Non-streaming data such as product details and orders via **Snowflake Marketplace**"
  },
  {
   "cell_type": "code",
   "id": "c8b59761-8282-4754-ab5e-69b1c1f73590",
   "metadata": {
    "language": "python",
    "name": "SharePoint",
    "collapsed": false,
    "resultHeight": 595,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# Define image in a stage and read the file\nimage=session.file.get_stream('@SKICAR.SKICAR_SCHEMA.SETUP/SharePoint.jpg' , decompress=False).read() \n\n# Display the image\nst.image(image, width=1200)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a8b4105e-1742-4dc3-a1f0-b5d7413b3e1e",
   "metadata": {
    "language": "python",
    "name": "SnowflakeMarketplaceSharePointConnector",
    "collapsed": false,
    "resultHeight": 631,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# Define image in a stage and read the file\nimage=session.file.get_stream('@SKICAR.SKICAR_SCHEMA.SETUP/SFMarketplace.jpg' , decompress=False).read() \n\n# Display the image\nst.image(image, width=1200)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9624ec12-c6a8-43d4-9dd4-6f1f9c75a455",
   "metadata": {
    "language": "sql",
    "name": "SharePointData"
   },
   "outputs": [],
   "source": "-- Example of a table creation and data load from SharePoint\nCREATE TABLE PRODUCT_INFO (\n    PRODUCT_ID VARCHAR,\n    PRODUCT_NAME VARCHAR,\n    PRODUCT_TYPE VARCHAR\n);\n\n-- Insert data into PRODUCT_INFO\nINSERT INTO PRODUCT_INFO VALUES\n('SKU-123', 'All-Season Tires', 'TIRE');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d5530d5-7d56-493f-a473-7c0939c81286",
   "metadata": {
    "name": "DataIngestion_Continued",
    "collapsed": false,
    "resultHeight": 44
   },
   "source": "2. **S3 Iceberg Tables**: Real-time streaming data stored in **Iceberg** format, directly queryable in Snowflake."
  },
  {
   "cell_type": "code",
   "id": "44c8d202-5ce3-4593-8ec1-ec48c953b449",
   "metadata": {
    "language": "python",
    "name": "s3_ApacheIcebergTables",
    "collapsed": false,
    "resultHeight": 604,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# Define image in a stage and read the file\nimage=session.file.get_stream('@SKICAR.SKICAR_SCHEMA.SETUP/s3.jpg' , decompress=False).read() \n\n# Display the image\nst.image(image, width=1200)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b09238c6-cc45-42d6-beb6-b2057cd85071",
   "metadata": {
    "name": "AccessIcebergTables",
    "collapsed": false,
    "resultHeight": 431
   },
   "source": "## **Querying Iceberg Tables in Snowflake**\n\nYou can **query Iceberg tables** in Snowflake directly. Iceberg is a **table format** supported by Snowflake, which allows you to perform queries using standard SQL.\n\n### **Key Points**:\n- **Standard SQL**: Once the data is stored in **Iceberg format**, you can query the table just like any other Snowflake table.\n\n### **Example SQL Query**:\nThe following query retrieves records from an **Iceberg table**:\n\n```sql\nSELECT * \nFROM my_iceberg_table\nWHERE order_status = 'IN_TRANSIT'\nORDER BY order_timestamp DESC;"
  },
  {
   "cell_type": "markdown",
   "id": "9dd6911d-4835-4a47-84eb-22f60db12530",
   "metadata": {
    "name": "DataPipeline",
    "collapsed": false,
    "resultHeight": 334
   },
   "source": "## Data Pipeline Overview\n\nThis diagram shows the **data pipeline** for processing and visualizing data from two sources:\n\n1. **SharePoint via Snowflake Marketplace Connector**: Data is ingested from SharePoint for further processing.\n2. **S3 Iceberg Tables**: Real-time streaming data is accessed directly from Iceberg tables for querying.\n\n### Key Points:\n- **Dynamic Tables**: Used to process and apply incremental updates to the data in real-time.\n- The DAG illustrates how data flows between the different tables, with dependencies showing the order of processing.\n\nBelow is the **graph** showing the flow of data through the pipeline.\n"
  },
  {
   "cell_type": "code",
   "id": "f282a737-4b4a-41ca-827c-53d3e0891879",
   "metadata": {
    "language": "python",
    "name": "DAG_Lineage",
    "collapsed": false,
    "resultHeight": 631,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# Define image in a stage and read the file\nimage=session.file.get_stream('@SKICAR.SKICAR_SCHEMA.SETUP/DAG.jpg' , decompress=False).read() \n\n# Display the image\nst.image(image, width=1200)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b803922a-c187-4f36-a45f-6ddd6d504e6b",
   "metadata": {
    "name": "CortexAnalystSemanticModel",
    "collapsed": false,
    "resultHeight": 486
   },
   "source": "## **Semantic Model Overview**\n\nThe **Semantic Model** defines the business logic and structure for querying data. It maps raw data to meaningful terms, allowing natural language queries to be processed effectively.\n\n### **Key Points**:\n- **Defines Business Logic**: The Semantic Model translates raw data into understandable business terms.\n- **Enables Natural Language Queries**: Allows **Cortex Analyst** to interpret user queries in natural language.\n\n### **How to Reference the Semantic Model**:\nThe **Semantic Model** is stored in a **Snowflake Stage** as a YAML file. You can reference this model in API calls to perform queries.\n\n```python\n# Python function to retrieve the Semantic Model path from Snowflake stage\ndef fetch_semantic_model():\n    # Path to the YAML file stored in the Snowflake Stage\n    model_path = f\"@SKICAR_SKICAR_SCHEMA_SETUP/SKICAR_Semantic_Model.yaml\"\n    return model_path"
  },
  {
   "cell_type": "markdown",
   "id": "6b52029b-035a-403f-beba-b3a7045e14f9",
   "metadata": {
    "name": "VerifiedQueryRepository",
    "collapsed": false,
    "resultHeight": 601
   },
   "source": "### **Using the Verified Query Repository**\n\nThe **Verified Query Repository** stores pre-approved SQL queries, ensuring that only validated and efficient queries are executed. This ensures optimized performance and superior query accuracy.\n\n#### **Key Points**:\n- **Stores Pre-approved Queries**: Manages and reuses efficient, validated queries.\n- **Ensures Efficient Query Execution**: Only tested and optimized queries are used by **Cortex Analyst**.\n\n#### **Example of a Verified Query**:\nThe following query compares the **average shipping time** for **Snowtires Automotive** against all other suppliers:\n\n```sql\n-- Example Verified Query to compare shipping times for 'Snowtires Automotive' vs. other suppliers\nselect DISTINCT(supplier_vendor_name), average_shipping_time \nfrom SKICAR.SKICAR_SCHEMA.SUPPLY_CHAIN \nwhere supplier_vendor_name = 'Snowtires Automotive'\nunion\nselect 'Other Suppliers' AS supplier_vendor_name, \navg(average_shipping_time) \nfrom (select DISTINCT(supplier_vendor_name), average_shipping_time \n      from SKICAR.SKICAR_SCHEMA.SUPPLY_CHAIN \n      where supplier_vendor_name <> 'Snowtires Automotive');"
  },
  {
   "cell_type": "markdown",
   "id": "da9a791a-64e2-40f4-8340-68412f8c0341",
   "metadata": {
    "name": "CortexAnalystRESTAPI",
    "collapsed": false,
    "resultHeight": 948
   },
   "source": "## **Cortex Analyst API Integration**\n\nThe **Cortex Analyst API** connects Snowflake with natural language queries, translating them using the **Semantic Model**, and returning results.\n\n### **Key Steps**:\n1. **Send Natural Language Query**: The user asks a question via Slack (or another interface).\n2. **API Call**: The query is sent to the **Cortex Analyst API**, which generates the corresponding SQL and returns the result.\n\n### **Endpoint for the Cortex Analyst API**:\n```python\n# Endpoint for Cortex Analyst REST API\nANALYST_ENDPOINT = f\"https://demo72.snowflakecomputing.com/api/v2/cortex/analyst/message\"\n```\n\n### **Function to Call the Cortex Analyst API:**\n```python\ndef query_cortex_analyst(question, model_path, pat_token):\n    headers = {\n        'Authorization': f'Bearer {pat_token}',  # Use Programmatic Access Token (PAT)\n        'Content-Type': 'application/json'\n    }\n    \n    # Prepare the request payload with the semantic model and query\n    data = {\n        \"semantic_model\": model_path,  # Path to your model in Snowflake stage\n        \"question\": question\n    }\n    \n    # Send POST request to the API\n    response = requests.post(ANALYST_ENDPOINT, headers=headers, json=data)\n    \n    if response.status_code == 200:\n        return response.json()\n    else:\n        raise Exception(f\"Error querying Cortex Analyst API: {response.status_code}, {response.text}\")\n```"
  },
  {
   "cell_type": "markdown",
   "id": "5792ea56-1398-4f07-a095-63fce4c748b6",
   "metadata": {
    "name": "cell1",
    "collapsed": false,
    "resultHeight": 508
   },
   "source": "## **Cortex Analyst API Integration via Slack**\n\nThis section demonstrates how the **Cortex Analyst API** is integrated with **Slack**, enabling users to query data directly through the chat interface. Users can submit questions via the **/askcortex** command, and the system processes these queries using the **Cortex Analyst API**.\n\nThis integration allows for real-time querying, providing immediate insights and seamless interaction with data through Slack.\n\n### **What You Saw**:\n- **Real-time Querying**: You saw how the **Cortex Analyst API** processes natural language queries from Slack and generates corresponding SQL queries to fetch the relevant data.\n- **Instant Insights**: The system returned immediate insights, answering queries such as \"What's the average shipping time from Snowtires Automotive?\" directly in Slack.\n  \n### **Demo Flow Summary**:\n1. **User Query**: The user asks a question via the **/askcortex** command in Slack.\n2. **Cortex Analyst API**: The query is sent to the **Cortex Analyst API**, which generates the appropriate SQL based on the **Semantic Model**.\n3. **SQL Execution**: The SQL is executed on the relevant Snowflake data sources, and the result is returned to the user.\n4. **Real-time Insights**: The user receives instant data insights, all through a conversational interface in Slack.\n\nBelow is a screenshot showing the **Cortex Analyst REST API** in action, processing a query directly from Slack using the **/askcortex** command.\n"
  },
  {
   "cell_type": "code",
   "id": "1ea43456-cfca-4b37-8980-d3c425627d79",
   "metadata": {
    "language": "python",
    "name": "Slack",
    "collapsed": false,
    "codeCollapsed": true,
    "resultHeight": 881
   },
   "outputs": [],
   "source": "# Define image in a stage and read the file\nimage=session.file.get_stream('@SKICAR.SKICAR_SCHEMA.SETUP/Slack.jpg' , decompress=False).read() \n\n# Display the image\nst.image(image, width=1200)",
   "execution_count": null
  }
 ]
}